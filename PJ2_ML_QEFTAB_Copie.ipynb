{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Project 2 - 2018\n",
    "## Fatine Benhsain - Tabish Qureshi - Ayyoub El Amrani\n",
    "### Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the project is to create a recommendation systems for movies based on data......bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to preprocess and use the data, the library pandas is used. The later provides very useful tools in this framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Importation & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is made for importing data and prepare them before implementing a machine learning method. The preprocessing includes steps such as exploration, wrangling... and can be used for feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Training Set Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('data/data_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting anything, the data will be explored in order to perform data wrangling and features engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are stacked into 2 columns with the Id rX_cY. X corresponds to a user and Y corresponds to the movie.\n",
    "In order to make a proper analysis, one needs to group users (same X) and the rating (Prediction) on movies (Y).\n",
    "For this sake, it is necessary to :\n",
    "1. Unstack the Id and separate X and Y\n",
    "2. Group the same X (users) as rows with corresponding movies (Y) as columns and the rating as argument of the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a method that will split the Id into two columns : _User_ and _Movie_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitting(df,column='Id'):\n",
    "    '''\n",
    "        df : the dataframe to split\n",
    "        column : the column containing the data to split, by default it is the Id column\n",
    "    '''\n",
    "    output = df[column].str.split('(\\d+)([A-z]+)(\\d+)', expand=True)\n",
    "    output = output.loc[:,[1,3]]\n",
    "    output.rename(columns={1:'User', 2:'y', 3:'Movie'}, inplace=True)\n",
    "    output['User'] = output['User'].astype(int)\n",
    "    output['Movie'] = output['Movie'].astype(int)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of the Id:\n",
    "split = splitting(raw_data)\n",
    "split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split['eval']=raw_data['Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the splitting is done, one needs to create a table to match users with the movies they rated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_table = split.pivot(index = 'User', columns = 'Movie', values = 'eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Now, the dataset is more readable and it is now possible to start analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to explore the data in order to have an overview of the dataset.\n",
    "\n",
    "It is possible for example to have an idea of:\n",
    "* The most/less watched movies\n",
    "* The most/less well rated\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 movies that have been rated:\n",
    "rating_table.isnull().describe().transpose().sort_values('freq').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 movies that have not been rated:\n",
    "rating_table.isnull().describe().transpose().sort_values('freq', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_table[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The distribution of the mean of the rating of each movie\n",
    "means = split.groupby('Movie').mean()\n",
    "means = means['eval']\n",
    "means.plot(kind='hist',figsize=(10,10),title='Distribution of the ratings of the movies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Alternating Least Squares (ALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les fonctions du cours ne sont pas compatibles avec les pandas DF, les données sont donc loadées autrement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = 'data/data_train.csv'\n",
    "ratings = load_data(path_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "test_rating = load_data('data/sample_submission.csv')\n",
    "\n",
    "test_rating.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Ratings per Movie & Users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 8, min # of users per item = 3.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_raw_data\n",
    "\n",
    "num_items_per_user, num_users_per_item = plot_raw_data(ratings)\n",
    "\n",
    "print(\"min # of items per user = {}, min # of users per item = {}.\".format(\n",
    "        min(num_items_per_user), min(num_users_per_item)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data between Traning & Testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    # init\n",
    "    num_rows, num_cols = valid_ratings.shape\n",
    "    train = sp.lil_matrix((num_rows, num_cols))\n",
    "    test = sp.lil_matrix((num_rows, num_cols))\n",
    "    \n",
    "    print(\"the shape of original ratings. (# of row, # of col): {}\".format(\n",
    "        ratings.shape))\n",
    "    print(\"the shape of valid ratings. (# of row, # of col): {}\".format(\n",
    "        (num_rows, num_cols)))\n",
    "\n",
    "    nz_items, nz_users = valid_ratings.nonzero()\n",
    "    \n",
    "    # split the data\n",
    "    for user in set(nz_users):\n",
    "        # randomly select a subset of ratings\n",
    "        row, col = valid_ratings[:, user].nonzero()\n",
    "        selects = np.random.choice(row, size=int(len(row) * p_test))\n",
    "        residual = list(set(row) - set(selects))\n",
    "\n",
    "        # add to train set\n",
    "        train[residual, user] = valid_ratings[residual, user]\n",
    "\n",
    "        # add to test set\n",
    "        test[selects, user] = valid_ratings[selects, user]\n",
    "\n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of original ratings. (# of row, # of col): (10000, 1000)\n",
      "the shape of valid ratings. (# of row, # of col): (9990, 999)\n",
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:1065253\n",
      "Total number of nonzero elements in test data:111620\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n",
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn Matrix Factorization using ALS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Perform the ALS model, one needs to initialize the parameters for the Matrix Factorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\" \n",
    "    Source: Lab 10 Solutions\n",
    "    \"\"\"\n",
    "    num_users, num_items = train.shape\n",
    "    user_features = np.random.rand(num_features, num_users)\n",
    "    item_features = np.random.rand(num_features, num_items)\n",
    "\n",
    "    # Sum up each ratings for each movie \n",
    "    item_sum = train.sum(axis=0)\n",
    "    item_nnz = train.getnnz(axis=0)\n",
    "\n",
    "    # set the first item features to the sum of the ratings divided by the number of nonzero items\n",
    "    for item_index in range(num_items):\n",
    "        item_features[0, item_index] = int(item_sum[0, item_index]/item_nnz[item_index])\n",
    "        \n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will update the user-feature matrix Z:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_feature(train, item_features, num_features, lambda_user, nz_user_itemindices):\n",
    "    num_users = train.shape[0]\n",
    "    user_features = np.zeros((num_features, num_users))\n",
    "\n",
    "    for user, items in nz_user_itemindices:\n",
    "        W = item_features[:, items]\n",
    "        \n",
    "        A = W @ W.T + lambda_user * sp.eye(num_features)\n",
    "        b = W @ train[user, items].T\n",
    "        \n",
    "        x = np.linalg.solve(A, b)\n",
    "        \n",
    "        user_features[:, user] = np.copy(x.T)\n",
    "        \n",
    "    return user_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will update the item-feature Matrix W:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_item_feature(train, user_features, num_features, lambda_item, nz_item_userindices):\n",
    "\n",
    "    num_items = train.shape[1]\n",
    "    item_features = np.zeros((num_features, num_items))\n",
    "\n",
    "    for item, users in nz_item_userindices:\n",
    "        W = user_features[:, users]\n",
    "        \n",
    "        A = W @ W.T + lambda_item * sp.eye(num_features)\n",
    "        b = W @ train[users, item]\n",
    "        \n",
    "        x = np.linalg.solve(A, b)\n",
    "        \n",
    "        item_features[:, item] = np.copy(x.T)\n",
    "        \n",
    "    return item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of the Mean Squared Error between predictions and nonzero train elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(data, user_features, item_features, nz):\n",
    "\n",
    "    mse = 0\n",
    "    pred = np.dot(user_features.T, item_features)\n",
    "    \n",
    "    for row, col in nz:\n",
    "        mse += np.square((data[row, col] - pred[row, col]))\n",
    "\n",
    "    return np.sqrt(mse/len(nz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is possible to perform ALS and compute errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_als(train, test, test_ratings, seed=988, num_features=15, m_iter=10, lambda_user=1., lambda_item=0.007, change=1, stop_criterion=1e-4):\n",
    "    \"\"\"\n",
    "    Use Alternating Least Squares (ALS) algorithm to generate predictions\n",
    "    \"\"\"\n",
    "    error_list = [0]\n",
    "    itr = 0\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Initialize W and Z with random small numbers\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # Group the indices by row or column index\n",
    "    nz_train, nz_user_itemindices, nz_item_userindices = build_index_groups(train)\n",
    "    \n",
    "    while change > stop_criterion and itr < m_iter:\n",
    "        \n",
    "        # Update W and Z\n",
    "        user_features = update_user_feature(train, item_features, num_features, lambda_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(train, user_features, num_features, lambda_item, nz_item_userindices)\n",
    "\n",
    "        rmse = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"RMSE on training set: {}.\".format(rmse))\n",
    "        change = np.fabs(rmse - error_list[-1])\n",
    "        error_list.append(rmse)\n",
    "        itr = itr + 1\n",
    "\n",
    "        # Calculate the RMSE\n",
    "        nnz_row, nnz_col = test.nonzero()\n",
    "        nnz_test = list(zip(nnz_row, nnz_col))\n",
    "        rmse = compute_error(test, user_features, item_features, nnz_test)\n",
    "        print(\"Test RMSE after running ALS: {s}\".format(s=rmse))\n",
    "\n",
    "        num_users = test_ratings.shape[0]\n",
    "        num_items = test_ratings.shape[1]\n",
    "        pred_als = sp.lil_matrix((num_users, num_items))\n",
    "    \n",
    "    # Multiply the 2 matrices to get X \n",
    "    for user in range(num_users):\n",
    "        for item in range(num_items):\n",
    "            item_info = item_features[:, item]\n",
    "            user_info = user_features[:, user]\n",
    "            pred_als[user, item] = user_info.T.dot(item_info)\n",
    "\n",
    "    return pred_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training set: 0.9138427641666631.\n",
      "Test RMSE after running ALS: 1.0680685243150878\n",
      "RMSE on training set: 0.8894586012503871.\n",
      "Test RMSE after running ALS: 1.0760310077303175\n",
      "RMSE on training set: 0.8756579032764699.\n",
      "Test RMSE after running ALS: 1.0792335347531201\n",
      "RMSE on training set: 0.8673220276225581.\n",
      "Test RMSE after running ALS: 1.0819458096154846\n",
      "RMSE on training set: 0.8621054545044858.\n",
      "Test RMSE after running ALS: 1.084910457268882\n",
      "RMSE on training set: 0.8585767704544748.\n",
      "Test RMSE after running ALS: 1.0876765766222312\n",
      "RMSE on training set: 0.8560585829649244.\n",
      "Test RMSE after running ALS: 1.0901101931320065\n",
      "RMSE on training set: 0.8541893176930065.\n",
      "Test RMSE after running ALS: 1.0922394948906404\n",
      "RMSE on training set: 0.8527543454993662.\n",
      "Test RMSE after running ALS: 1.0941118747966565\n",
      "RMSE on training set: 0.8516200367346703.\n",
      "Test RMSE after running ALS: 1.0957802587912941\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 999 is out of bounds for axis 1 with size 999",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-60a9f09a18a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_als\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-9b342a4e265f>\u001b[0m in \u001b[0;36mcalculate_als\u001b[0;34m(train, test, test_ratings, seed, num_features, m_iter, lambda_user, lambda_item, change, stop_criterion)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mitem_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0muser_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mpred_als\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 999 is out of bounds for axis 1 with size 999"
     ]
    }
   ],
   "source": [
    "prediction = calculate_als(train, test, test_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rating.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predictions on the submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first open the csv containing the sample in order to obtain the testing data, we then split this data to get the users and movies in seperate columns using our defined method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = splitting(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
