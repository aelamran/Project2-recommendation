{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = 'data/data_train.csv'\n",
    "ratings = load_data(path_dataset)\n",
    "\n",
    "test_rating = load_data('data/sample_submission.csv')\n",
    "\n",
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= 0)[0]\n",
    "    valid_items = np.where(num_users_per_item >= 0)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    # init\n",
    "    num_rows, num_cols = valid_ratings.shape\n",
    "    train = sp.lil_matrix((num_rows, num_cols))\n",
    "    test = sp.lil_matrix((num_rows, num_cols))\n",
    "    \n",
    "    print(\"the shape of original ratings. (# of row, # of col): {}\".format(\n",
    "        ratings.shape))\n",
    "    print(\"the shape of valid ratings. (# of row, # of col): {}\".format(\n",
    "        (num_rows, num_cols)))\n",
    "\n",
    "    nz_items, nz_users = valid_ratings.nonzero()\n",
    "    \n",
    "    # split the data\n",
    "    for user in set(nz_users):\n",
    "        # randomly select a subset of ratings\n",
    "        row, col = valid_ratings[:, user].nonzero()\n",
    "        selects = np.random.choice(row, size=int(len(row) * p_test))\n",
    "        residual = list(set(row) - set(selects))\n",
    "\n",
    "        # add to train set\n",
    "        train[residual, user] = valid_ratings[residual, user]\n",
    "\n",
    "        # add to test set\n",
    "        test[selects, user] = valid_ratings[selects, user]\n",
    "\n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test\n",
    "\n",
    "def init_MF(train, num_features):\n",
    "    \"\"\" \n",
    "    Source: Lab 10 Solutions\n",
    "    \"\"\"\n",
    "    num_users, num_items = train.shape\n",
    "    user_features = np.random.rand(num_features, num_users)\n",
    "    item_features = np.random.rand(num_features, num_items)\n",
    "\n",
    "    # Sum up each ratings for each movie \n",
    "    item_sum = train.sum(axis=0)\n",
    "    item_nnz = train.getnnz(axis=0)\n",
    "\n",
    "    # set the first item features to the sum of the ratings divided by the number of nonzero items\n",
    "    for item_index in range(num_items):\n",
    "        item_features[0, item_index] = int(item_sum[0, item_index]/item_nnz[item_index])\n",
    "        \n",
    "    return user_features, item_features\n",
    "\n",
    "def update_user_feature(train, item_features, num_features, lambda_user, nz_user_itemindices):\n",
    "    num_users = train.shape[0]\n",
    "    user_features = np.zeros((num_features, num_users))\n",
    "\n",
    "    for user, items in nz_user_itemindices:\n",
    "        W = item_features[:, items]\n",
    "        \n",
    "        A = W @ W.T + lambda_user * sp.eye(num_features)\n",
    "        b = W @ train[user, items].T\n",
    "        \n",
    "        x = np.linalg.solve(A, b)\n",
    "        \n",
    "        user_features[:, user] = np.copy(x.T)\n",
    "        \n",
    "    return user_features\n",
    "\n",
    "def update_item_feature(train, user_features, num_features, lambda_item, nz_item_userindices):\n",
    "\n",
    "    num_items = train.shape[1]\n",
    "    item_features = np.zeros((num_features, num_items))\n",
    "\n",
    "    for item, users in nz_item_userindices:\n",
    "        W = user_features[:, users]\n",
    "        \n",
    "        A = W @ W.T + lambda_item * sp.eye(num_features)\n",
    "        b = W @ train[users, item]\n",
    "        \n",
    "        x = np.linalg.solve(A, b)\n",
    "        \n",
    "        item_features[:, item] = np.copy(x.T)\n",
    "        \n",
    "    return item_features\n",
    "\n",
    "def compute_error(data, user_features, item_features, nz):\n",
    "\n",
    "    mse = 0\n",
    "    pred = np.dot(user_features.T, item_features)\n",
    "    \n",
    "    for row, col in nz:\n",
    "        mse += np.square((data[row, col] - pred[row, col]))\n",
    "\n",
    "    return np.sqrt(mse/len(nz))\n",
    "\n",
    "def calculate_als(train, test, test_ratings, seed=988, num_features=100, m_iter=10, lambda_user=1., lambda_item=0.001, change=1, stop_criterion=1e-8):\n",
    "    \"\"\"\n",
    "    Use Alternating Least Squares (ALS) algorithm to generate predictions\n",
    "    \"\"\"\n",
    "    error_list = [0]\n",
    "    itr = 0\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Initialize W and Z with random small numbers\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # Group the indices by row or column index\n",
    "    nz_train, nz_user_itemindices, nz_item_userindices = build_index_groups(train)\n",
    "    \n",
    "    while change > stop_criterion and itr < m_iter:\n",
    "        \n",
    "        # Update W and Z\n",
    "        user_features = update_user_feature(train, item_features, num_features, lambda_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(train, user_features, num_features, lambda_item, nz_item_userindices)\n",
    "\n",
    "        rmse = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"RMSE on training set: {}.\".format(rmse))\n",
    "        change = np.fabs(rmse - error_list[-1])\n",
    "        error_list.append(rmse)\n",
    "        itr = itr + 1\n",
    "\n",
    "    # Calculate the RMSE\n",
    "    nnz_row, nnz_col = test.nonzero()\n",
    "    nnz_test = list(zip(nnz_row, nnz_col))\n",
    "    rmse = compute_error(test, user_features, item_features, nnz_test)\n",
    "    print(\"Test RMSE after running ALS: {s}\".format(s=rmse))\n",
    "\n",
    "    num_users = test_ratings.shape[0]\n",
    "    num_items = test_ratings.shape[1]\n",
    "    pred_als = sp.lil_matrix((num_users, num_items))\n",
    "    \n",
    "    # Multiply the 2 matrices to get X \n",
    "    for user in range(num_users):\n",
    "        for item in range(num_items):\n",
    "            item_info = item_features[:, item]\n",
    "            user_info = user_features[:, user]\n",
    "            pred_als[user, item] = user_info.T.dot(item_info)\n",
    "\n",
    "    return pred_als\n",
    "\n",
    "prediction = calculate_als(train, test, test_rating)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
